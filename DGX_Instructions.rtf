{\rtf1\ansi\ansicpg1252\cocoartf2821
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;\f2\fnil\fcharset0 HelveticaNeue;
}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid1\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs36 \cf0 Model Training on DGX:
\f1\b0\fs24 \
\

\fs28 To run the model Training code, need to setup the environment and run the following commands:
\fs24 \
\
\pard\tx220\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\pardirnatural\partightenfactor0
\ls1\ilvl0\cf0 {\listtext	1.	}
\fs26 tmux new -s alpha
\fs24 \
\pard\tx220\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\sl480\slmult1\pardirnatural\partightenfactor0
\ls1\ilvl0\cf0 {\listtext	2.	}
\fs26 tmux attach -t alpha
\fs24 \
{\listtext	3.	}
\f2\fs26 NV_GPU=\'914,7\'92 nvidia-docker run -it -v <path-to-model-code directory on DGX>:<path-to-model-code directory on DGX> {\field{\*\fldinst{HYPERLINK "http://nvcr.io/nvidia/pytorch:21.06-py3"}}{\fldrslt nvcr.io/nvidia/pytorch:21.06-py3}}\
\ls1\ilvl0
\f1\fs24 {\listtext	4.	}
\fs26 cd <model-code directory>
\fs24 \
{\listtext	5.	}
\fs26 pip install tensorflow
\fs24 \
{\listtext	6.	}
\fs26 pip install shap
\fs24 \
{\listtext	7.	}
\fs26 pip install transformers
\fs24 \
\ls1\ilvl0{\listtext	8.	}
\fs26 pip install --upgrade scikit-learn
\fs24 \
{\listtext	9.	}
\fs26 pip install numpy==1.21.0
\fs24 \
{\listtext	10.	}
\fs26 python bert_training.py
\fs24 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\sl480\slmult1\pardirnatural\partightenfactor0
\cf0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\sl336\slmult1\pardirnatural\partightenfactor0
\cf0 After running these commands, it\'92ll take 6-7 hours on DGX to train the models and after training is complete in the model-code directory, there will be some .png files corresponding to accuracy and loss graph and shap explanation and .pth file to save the best model which has the highest accuracy and .log file for logging the whole training process.\
}